{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c44a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_repetition_kit as trk\n",
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4edb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config for this run\n",
    "ASR_df_filepath = '../repetition_data_generation/data/rep_audio.csv'\n",
    "\n",
    "config = dict(\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.01,\n",
    "    dataset=ASR_df_filepath,\n",
    "    hid_dim=256,\n",
    "    enc_layers=4,\n",
    "    dec_layers=4,\n",
    "    enc_heads=8,\n",
    "    dec_heads=8,\n",
    "    enc_pf_dim=512,\n",
    "    dec_pf_dim=512,\n",
    "    enc_dropout=0.1,\n",
    "    dec_dropout=0.2,\n",
    "    clip=1,\n",
    "    bpe_vocab_size=1600,\n",
    "    decode_trg = True,\n",
    "    early_stop = 6\n",
    ")\n",
    "\n",
    "asr_text_filepath = 'asr.txt'\n",
    "ttx_text_filepath = 'ttx.txt'\n",
    "train_filename = 'train_sentence.csv'\n",
    "valid_filename = 'valid_sentence.csv'\n",
    "test_filename = 'test_sentence.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37dcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scr\n",
    "import pandas as pd\n",
    "df = pd.read_csv(ASR_df_filepath, names=['',\n",
    "                                             'audio_path',\n",
    "                                             'asr_transcript',\n",
    "                                             'original_text',\n",
    "                                             'mutated_text',\n",
    "                                             'index_tags',\n",
    "                                             'err_tags'], header=None, index_col='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad7ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trk.load_data(ASR_df_filepath = ASR_df_filepath,\n",
    "              train_filename = train_filename,\n",
    "              valid_filename = valid_filename,\n",
    "              test_filename = test_filename,\n",
    "              asr_text_filepath = asr_text_filepath,\n",
    "              ttx_text_filepath = ttx_text_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132fb5da",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = trk.create_train_bpe_tokenizer(config['bpe_vocab_size'],\n",
    "                                           asr_text_filepath = \\\n",
    "                                           asr_text_filepath,\n",
    "                                           ttx_text_filepath = ttx_text_filepath,\n",
    "                                           save_tokenizer = True,\n",
    "                                           tokenizer_filename = \"./tokenizer-test.json\"\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230f747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, TTX, TRG, ASR = \\\n",
    "    trk.produce_iterators(train_filename,\n",
    "                          valid_filename,\n",
    "                          test_filename,\n",
    "                          asr_tokenizer=tokenizer,\n",
    "                          ttx_tokenizer=tokenizer\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f430c522",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['H', 'el', 'lo', ',', 'y', \"'\", 'all', '!', 'H', 'ow', 'are', 'you', '[UNK]', '?', '[', 'W', 'S', 'P', ']']\n[32, 803, 294, 13, 79, 8, 329, 5, 32, 592, 275, 416, 0, 23, 51, 47, 43, 40, 53]\n"
     ]
    }
   ],
   "source": [
    "# Test out the tokenizer\n",
    "output = tokenizer.encode(\"Hello, y'all! How are you üòÅ ? [WSP]\")\n",
    "print(output.tokens)\n",
    "print(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09a97dc",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['m', 'ut', 'ated', '_', 'text'] \n ['or', 'ig', 'in', 'al', '_', 'text'] \n [''] \n\n['member', 'ship', 'of', 'parliament', ':', 'see', ',,,', 'of', 'parliament', ':', 'see', 'min', 'utes', ',,,', 'min', 'utes'] \n ['Member', 'ship', 'of', 'Parliament', ':', 'see', 'M', 'in', 'utes'] \n [''] \n\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(train_data): \n",
    "    if i<2: print(t.true_text,'\\n',t.asr,'\\n',t.tags,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f268cc2b",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e631a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e5475f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwitw\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "c:\\users\\carl\\documents\\projects\\running_records\\test_rr_venv2\\lib\\site-packages\\IPython\\html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.31<br/>\n                Syncing run <strong style=\"color:#cdcd00\">helpful-sun-38</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/witw/running_records\" target=\"_blank\">https://wandb.ai/witw/running_records</a><br/>\n                Run page: <a href=\"https://wandb.ai/witw/running_records/runs/3to6rddf\" target=\"_blank\">https://wandb.ai/witw/running_records/runs/3to6rddf</a><br/>\n                Run data is saved locally in <code>C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\wandb\\run-20210901_144054-3to6rddf</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,145,289 trainable parameters\n",
      "Loss after 00400 examples: 1.573\n",
      "Loss after 00800 examples: 1.548\n",
      "Loss after 01200 examples: 1.528\n",
      "Loss after 01600 examples: 0.988\n",
      "Loss after 02000 examples: 1.082\n",
      "\n",
      "RuntimeError! Skipping this batch, using previous loss as est\n",
      "\n",
      "Loss after 02400 examples: 1.127\n",
      "\n",
      "RuntimeError! Skipping this batch, using previous loss as est\n",
      "\n",
      "Loss after 02800 examples: 0.976\n",
      "Loss after 03200 examples: 1.013\n",
      "Loss after 03600 examples: 0.957\n",
      "Loss after 04000 examples: 0.970\n",
      "Loss after 04400 examples: 1.130\n",
      "Loss after 04800 examples: 1.114\n",
      "Loss after 05200 examples: 1.068\n",
      "Loss after 05600 examples: 1.013\n",
      "Loss after 06000 examples: 1.047\n",
      "\n",
      "RuntimeError! Skipping this batch, using previous loss as est\n",
      "\n",
      "Loss after 06400 examples: 1.031\n",
      "Loss after 06787 examples: 1.023\n",
      "\n",
      "RuntimeError! Skipping this batch, using previous loss as est\n",
      "\n",
      "Loss after 07187 examples: 1.030\n",
      "Loss after 07587 examples: 0.944\n",
      "Loss after 07987 examples: 1.012\n",
      "Epoch: 01 | Time: 2m 4s\n",
      "\tTrain Loss: 1.127 | Train PPL:   3.086\n",
      "\t Val. Loss: 1.047 |  Val. PPL:   2.849\n",
      "Loss after 08387 examples: 1.095\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 4504<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\wandb\\run-20210901_144054-3to6rddf\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\wandb\\run-20210901_144054-3to6rddf\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_runtime</td><td>139</td></tr><tr><td>_timestamp</td><td>1630521793</td></tr><tr><td>_step</td><td>8387</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>1.09529</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_runtime</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>_timestamp</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>_step</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà</td></tr><tr><td>loss</td><td>‚ñà‚ñà‚ñá‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">helpful-sun-38</strong>: <a href=\"https://wandb.ai/witw/running_records/runs/3to6rddf\" target=\"_blank\">https://wandb.ai/witw/running_records/runs/3to6rddf</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12672/1014537498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = trk.model_pipeline(config, \n\u001b[0m\u001b[0;32m      2\u001b[0m                            \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                            \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                            \u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                            \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[1;34m(hyperparameters, device, train_data, valid_data, test_data, TTX, TRG, ASR)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# and use them to train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;31m# and test its final performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_iterator, valid_iterator, criterion, optimizer, config)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nRuntimeError! Skipping this batch, using previous loss as est\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(model, batch, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carl\\documents\\projects\\running_records\\test_rr_venv2\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\carl\\documents\\projects\\running_records\\test_rr_venv2\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = trk.model_pipeline(config, \n",
    "                           device,\n",
    "                           train_data,\n",
    "                           valid_data,\n",
    "                           test_data,\n",
    "                           TTX,\n",
    "                           TRG,\n",
    "                           ASR\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b1603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3811jvsc74a57bd00d898c91cdbd1d547a032e40fd9fc4a4593d3423d98c62ef5f30b40db9c0dc8a",
   "display_name": "Python 3.8.11 64-bit ('rr_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "metadata": {
   "interpreter": {
    "hash": "0d898c91cdbd1d547a032e40fd9fc4a4593d3423d98c62ef5f30b40db9c0dc8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}