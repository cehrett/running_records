{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c44a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_repetition_kit as trk\n",
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4edb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config for this run\n",
    "ASR_df_filepath = '..\\\\repetition_data_generation\\\\data\\\\generated_data.csv'\n",
    "\n",
    "config = dict(\n",
    "    epochs=5,\n",
    "    batch_size=12,\n",
    "    learning_rate=0.0005,\n",
    "    dataset=ASR_df_filepath,\n",
    "    hid_dim=256,\n",
    "    enc_layers=4,\n",
    "    dec_layers=4,\n",
    "    enc_heads=8,\n",
    "    dec_heads=8,\n",
    "    enc_pf_dim=512,\n",
    "    dec_pf_dim=512,\n",
    "    enc_dropout=0.1,\n",
    "    dec_dropout=0.2,\n",
    "    clip=1,\n",
    "    bpe_vocab_size=1200,\n",
    "    decode_trg = False,\n",
    "    early_stop = 3\n",
    ")\n",
    "\n",
    "asr_text_filepath = 'asr.txt'\n",
    "ttx_text_filepath = 'ttx.txt'\n",
    "train_filename = 'train_sentence.csv'\n",
    "valid_filename = 'valid_sentence.csv'\n",
    "test_filename = 'test_sentence.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37dcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad7ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py:48: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.tags = df.tags.str.replace(r'\\n', '')\n"
     ]
    }
   ],
   "source": [
    "trk.load_data(ASR_df_filepath = ASR_df_filepath,\n",
    "              train_filename = train_filename,\n",
    "              valid_filename = valid_filename,\n",
    "              test_filename = test_filename,\n",
    "              asr_text_filepath = asr_text_filepath,\n",
    "              ttx_text_filepath = ttx_text_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132fb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = trk.create_train_bpe_tokenizer(config['bpe_vocab_size'],\n",
    "                                           asr_text_filepath = \\\n",
    "                                           asr_text_filepath,\n",
    "                                           ttx_text_filepath = ttx_text_filepath,\n",
    "                                           save_tokenizer = True,\n",
    "                                           tokenizer_filename = \".\\\\tokenizer-test.json\"\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230f747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, TTX, TRG, ASR = \\\n",
    "    trk.produce_iterators(train_filename,\n",
    "                          valid_filename,\n",
    "                          test_filename,\n",
    "                          tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f430c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', 'el', 'lo', ',', 'y', \"'\", 'all', '!', '[UNK]', 'ow', 'are', 'you', '[UNK]', '?', '[', '[UNK]', '[UNK]', '[UNK]', ']']\n",
      "[0, 687, 179, 12, 56, 8, 217, 5, 0, 514, 164, 293, 0, 28, 29, 0, 0, 0, 30]\n"
     ]
    }
   ],
   "source": [
    "# Test out the tokenizer\n",
    "output = tokenizer.encode(\"Hello, y'all! How are you üòÅ ? [WSP]\")\n",
    "print(output.tokens)\n",
    "print(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09a97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'have', 'adopted', 'further', 'measures', 'of', 'a', 'procedural', 'nature'] \n",
      " ['we', 'have', 'adopted', 'further', 'measures', 'of', 'a', 'proced', 'ural', 'nat', 'ure'] \n",
      " [\"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'RB2'\", \"'O'\", \"'O'\"] \n",
      "\n",
      "['as', 'a', 'result', 'of', 'the', 'crisis', 'in', 'the', 'next', 'few', 'years', 'the', 'situation', 'will', 'only', 'get', 'worse'] \n",
      " ['result', 'of', 'the', 'crisis', 'in', 'the', 'next', 'fe', 'w', 'years', 'the', 'situation', 'will', 'only', 'get', 'next', 'fe', 'w', 'years', 'the', 'situation', 'will', 'only', 'ye', 't', 'next', 'fe', 'w', 'years', 'the', 'situation', 'will', 'only', 'get', 'wor', 'se'] \n",
      " [\"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'O'\", \"'RB3'\", \"'RI3'\", \"'RI3'\", \"'RI3'\", \"'RI3'\", \"'RI3'\", \"'RI3'\", \"'RI3'\", \"'O'\"] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(train_data): \n",
    "    if i<2: print(t.true_text,'\\n',t.asr,'\\n',t.tags,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f268cc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e631a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5475f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mwitw\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.31<br/>\n                Syncing run <strong style=\"color:#cdcd00\">faithful-cherry-51</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/witw/running_records\" target=\"_blank\">https://wandb.ai/witw/running_records</a><br/>\n                Run page: <a href=\"https://wandb.ai/witw/running_records/runs/gn6ppuks\" target=\"_blank\">https://wandb.ai/witw/running_records/runs/gn6ppuks</a><br/>\n                Run data is saved locally in <code>C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\wandb\\run-20220221_105845-gn6ppuks</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,618,185 trainable parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 11232<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\wandb\\run-20220221_105845-gn6ppuks\\logs\\debug.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>C:\\Users\\Carl\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\wandb\\run-20220221_105845-gn6ppuks\\logs\\debug-internal.log</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_runtime</td><td>16</td></tr><tr><td>_timestamp</td><td>1645459141</td></tr><tr><td>_step</td><td>0</td></tr></table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_runtime</td><td>‚ñÅ</td></tr><tr><td>_timestamp</td><td>‚ñÅ</td></tr><tr><td>_step</td><td>‚ñÅ</td></tr></table><br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">faithful-cherry-51</strong>: <a href=\"https://wandb.ai/witw/running_records/runs/gn6ppuks\" target=\"_blank\">https://wandb.ai/witw/running_records/runs/gn6ppuks</a><br/>\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_25156/442083778.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m model = trk.model_pipeline(config, \n\u001B[0m\u001B[0;32m      2\u001B[0m                            \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                            \u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                            \u001B[0mvalid_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                            \u001B[0mtest_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py\u001B[0m in \u001B[0;36mmodel_pipeline\u001B[1;34m(hyperparameters, device, train_data, valid_data, test_data, TTX, TRG, ASR)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;31m# and use them to train the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_iterator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalid_iterator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m         \u001B[1;31m# and test its final performance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, train_iterator, valid_iterator, criterion, optimizer, config)\u001B[0m\n\u001B[0;32m    325\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_iterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    326\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 327\u001B[1;33m                 \u001B[0mbatch_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCLIP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    328\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    329\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\nRuntimeError! Skipping this batch, using previous loss as est\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Projects\\Running_records\\running_records\\transformer_models\\transformer_repetition_kit.py\u001B[0m in \u001B[0;36mtrain_batch\u001B[1;34m(model, batch, optimizer, criterion, clip)\u001B[0m\n\u001B[0;32m    383\u001B[0m     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 385\u001B[1;33m     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    386\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    387\u001B[0m     \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclip_grad_norm_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclip\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\carl\\documents\\projects\\running_records\\test_rr_venv2\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    253\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    254\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 255\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    256\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\carl\\documents\\projects\\running_records\\test_rr_venv2\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    145\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 147\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    148\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = trk.model_pipeline(config, \n",
    "                           device,\n",
    "                           train_data,\n",
    "                           valid_data,\n",
    "                           test_data,\n",
    "                           TTX,\n",
    "                           TRG,\n",
    "                           ASR\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}