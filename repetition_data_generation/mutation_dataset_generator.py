# Functions for creating mutation datasets
# Author: Porter Zach
# This is an extension and modification of the existing file
# "text_and_audio_repetition_generation.py", extended to work
# with all mutations generated by "text_mutation_generation.py".

from text_mutation_generation import mutate_selectively
import tts_data_generation
from nemo_asr_transcript_generation import get_asr_transcript
import pandas as pd
import gc
import torch

def generate_mutated_text_tags_audio(sentence: str, mutation_type: str):
    """
    Takes as input a sentence and delivers as output a reading of that sentence both as text and as audio,
    along with tags describing the mutations in terms of the indices of the words in the original sentence.
    :param sentence:str
    :param mutation_type:str
    :return: triple (new_text,tags,audio) where new_text is the new text, tags is a list of indices 
    describing the mutations, and audio is the audio of the mutation-reading.
    """
    new_text, tags = mutate_selectively(sentence, mutation_type, remove_punc=False)
    audio = tts_data_generation.text_to_audio_specv(new_text)
    return new_text, tags, audio

def create_dataset(sentences: list, filename: str, mutation_type: str, root='.\\data\\', start_idx=0, save_csv=False):
    """
    Creates a dataset of mutation-laden readings of sentences, complete with tags.

    :param sentences: A list of strings, the sentences to be read and tagged.
    :param filename: The filename under which the resulting csv is to be written. Do not include .csv extension. This will also be used for the .wav files.
    :param root: The location where the csv and audio files will be placed.
    :return:
    """
    true_text = []
    tags = []
    mut_audio_filenames = []

    for i, sentence in enumerate(sentences):
        # Try to free up CUDA memory
        gc.collect()
        torch.cuda.empty_cache()

        mut_text, mut_tags, mut_audio = generate_mutated_text_tags_audio(sentence, mutation_type)
        true_text.append(sentence)
        tags.append(mut_tags)

        # Write audio to wav files
        mut_audio_filename = root + 'audio\\' + filename+str(i+start_idx)+'.wav'
        tts_data_generation.save_audio(mut_audio, mut_audio_filename)
        mut_audio_filenames.append(mut_audio_filename)

    # Get ASR transcript
    rep_asr = get_asr_transcript(mut_audio_filenames)

    # Make pandas DF of true texts, tags, audio filenames, and asr transcripts.
    data = {'true_text':true_text, 'tags': tags, 'filepath': mut_audio_filenames, 'asr': rep_asr}
    rep_df = pd.DataFrame(data=data)

    # Save DF to csv
    if save_csv:
        csv_filename = root + filename + '.csv'
        rep_df.to_csv(csv_filename)
    else:
        return rep_df


if __name__ == '__main__':
    import pandas as pd
    import soundfile as sf
    from nemo_asr_transcript_generation import get_asr_transcript

    train_sentences = ['Of the training sentences included in this dataset, this one is the first.',
                       'There are multiple sentences in this dataset: for example, this one contains one contains one '
                       'contains a repetition.',
                       'Some days you get the bear, and some days, well, some days... oh boy.',
                       'The previous sentence was a notable non sequitur of a particularly ursine flavor.',
                       'This is explicitly not a coded warning that there is a bear standing behind you right now.']

    valid_sentences = ['The sentences listed here are not valid sentences in the sense that the sentences are valid, '
                       'but rather in the sense that the sentences are for the validation set.',
                       'Quite a long one, that first validation sentence was.',
                       'Without a pair of boots, stomping capacity is typically diminished.',
                       'Where some books are about spiders, other books are instead about woodworking, and a subset '
                       'of these books have spiders physically present on top of them.']

    test_sentences = ['Here is one test sentence',
                      'Oh I guess this is a second test sentence!',
                      "Well, what do you know - it's a third test sentence.",
                      "This fourth test sentence might be the best one yet, don't you think?",
                      "Never mind, this fifth and final test sentence is pretty obviously the greatest of all time."]

    create_dataset(train_sentences, 'train_sentence', save_csv=True)
    create_dataset(valid_sentences, 'valid_sentence', save_csv=True)
    create_dataset(test_sentences, 'test_sentence', save_csv=True)
